---
title: "area_code_report"
author: "areeves"
date: "December 1, 2017"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Collect and Process /r/glassine Dataset

Load the relevant libraries:
```{r}
library(RedditExtractoR)
library(stringr)
library(knitr)
```

Check whether the raw data is available in the working directory. If it isn't collect the data from the web.
```{r}

if (file.exists("glassine_urls.csv")) {
  glassine_urls <- read.csv("glassine_urls.csv")
} else {
  glassine_urls <- reddit_urls(subreddit = "glassine",page_threshold = 40)
}

if (file.exists("area_codes_by_state.csv")) {
  area_codes_by_state <- read.csv("area_codes_by_state.csv")
} else {
  sprintf("use URL to get xls file -- file.download() didn't work for me")
}

```
[Click here for the area codes by state table if the data loading failed](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwi2lb79huDXAhWq0FQKHeQ0A9EQFggoMAA&url=http%3A%2F%2Fmedia.juiceanalytics.com%2Fdownloads%2Farea_codes_by_state.xls&usg=AOvVaw3xPwQBSxfXDIqjnq6etEWn)

Examine the glassine data to decide how to parse the content.
```{r}
summary(glassine_urls)
head(glassine_urls)
```
The "title" column of the dataset mentions the area code for each thread. One possible parsing procedure could extract any three-digit number within the title column. This will produce an array of candidate area codes.
```{r}
candidate_area_codes<-str_extract(glassine_urls$title, "[0-9]{3}")
```

Create frequency table for area code mentions:
```{r}
ac_tbl<-as.data.frame(sort(table(candidate_area_codes),decreasing=TRUE))
kable(ac_tbl,align='ccc')
```
Some of these candidates are not area codes; e.g. '007'. However, most candidates do have a corresponding area code. We can validate our candidates against the independent dataset from the **area_codes_by_state** data in the **Area.code** column.
```{r}
valid_ac<-ac_tbl$candidate_area_codes %in% area_codes_by_state$Area.code
kable(ac_tbl[!valid_ac,],align='ccc')
```
After removing the invalid candidates, the frequency table is ready to be used for constructing the cholopleth maps for /r/glassine mentions.
```{r}
valid_ac<-ac_tbl$candidate_area_codes %in% area_codes_by_state$Area.code
ac_tbl<-ac_tbl[valid_ac,]
kable(ac_tbl,align='ccc')
```

#Collect and process shapefile data

Cholopleth maps shade different map regions according to a variable of interest. In this case, the shading will reflect the number of mentions a given area code has in the glassine dataset. But to shade a given map region we will have to first define its location. This involves finding data that delineates the extent of the area codes within USA.

I'm getting ahead of myself a bit here, but I'm including one more processing step on the frequency table. This is because of a plotting issue I run into later on with the maps. The essence of the problem is that these low-count area codes completely overlap with some high-count area codes, making it difficult to see the shading for the high-count area codes. There is probably a more elegant way of handling the problem. For now, here's the hard-coded step:
```{r}
ac_tbl<-ac_tbl[!(names(ac_tbl) %in% c("267","862"))]
```

Load map-making libraries:
```{r}
# load up libraries:
library(maptools)
library(sp)
library(rgdal)
library(RColorBrewer)
library(ggplot2)
library(broom)
library(ggmap)
library(rgeos)
```


Unzip the AreaCode.zip file to extract the AreaCode.shp file delineating the 
extent of each area code in lat,lon coordinates. Read in the .shp file and then 
remove all extracted files to clear up space.

```{r}
if (file.exists("AreaCode.zip")) {
  unzip("AreaCode.zip")
  area <- readOGR("AreaCode.shp")
} else {
  download.file("https://www.sciencebase.gov/catalog/file/get/4f4e4a19e4b07f02db605716?facet=AreaCode","AreaCode.zip",mode="wb")
  unzip("AreaCode.zip")
  area <- readOGR("AreaCode.shp")
}

file.remove("AreaCode.dbf","AreaCode.prj","AreaCode.sbn",
            "AreaCode.sbx","AreaCode.shx","AreaCode.shp","AreaCode.shp.xml")
```

select shapes only for area codes mentioned in the frequency table
```{r}

glassine_area<-area[area$NPA %in% ac_tbl$candidate_area_codes,]
```

add a column of data indicating number of mentions per area code
```{r}

ac_ref<-match(glassine_area@data$NPA,ac_tbl$candidate_area_codes)
glassine_area@data$TALLY <- as.vector(ac_tbl[ac_ref,2])
```

For area code labels, use the centroid of an area code, which is found using a function in the rgeos package. Find lat,lon of centroids and add them as two columns of data.
```{r}

glassine_area$CENTER.x<-tidy(gCentroid(glassine_area, byid=TRUE))[,1]
glassine_area$CENTER.y<-tidy(gCentroid(glassine_area, byid=TRUE))[,2]
```

Make proper transform -- not sure if this is necessary
```{r}

glassine_WGS84 <- spTransform(glassine_area, CRS("+init=epsg:4326"))
glassine_df_WGS84 <- tidy(glassine_WGS84)
glassine_WGS84$polyID <- sapply(slot(glassine_WGS84, "polygons"), function(x) slot(x, "ID"))
glassine_df_WGS84 <- merge(glassine_df_WGS84, glassine_WGS84, by.x = "id", by.y="polyID")
```

# Cholopleth Maps of /r/glassine Dataset

Create a cholopleth map of mainland USA
```{r}

usa_basemap <- get_map(location="United States", zoom=4, maptype = 'satellite')

ggmap(usa_basemap) +
        geom_polygon(data = glassine_df_WGS84, 
                     aes(x=long, y=lat, group = group, # coordinates, and group them by polygons
                         fill = TALLY), alpha = 0.5) + # variable to use for filling
        scale_fill_gradient(low="#bfefff",high="red")+
        ggtitle("Area Code Mentions in /r/glassine")
```

Create a cholopleth map of PA-NJ region
```{r}

pa_basemap <- get_map(location="PA", zoom=6, maptype = 'satellite')

ggmap(pa_basemap) +
        geom_polygon(data = glassine_df_WGS84, 
                    aes(x=long, y=lat, group = group, # coordinates, and group them by polygons
                        fill = TALLY), alpha = .8) + # variable to use for filling
        scale_fill_gradient(low="#bfefff",high="red")+
        geom_text(data = glassine_df_WGS84,aes(x=CENTER.x,y=CENTER.y,
                        label=ifelse(TALLY>20,as.character(NPA),'')))+
        ggtitle("Area Code Mentions in /r/glassine")
```

